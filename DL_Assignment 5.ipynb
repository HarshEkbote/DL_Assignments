{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86e7061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\avadh\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\avadh\\anaconda3\\lib\\site-packages (from gensim) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\avadh\\anaconda3\\lib\\site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\avadh\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\avadh\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193c661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf960936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avadh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avadh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e6425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's \n",
    "standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type \n",
    "specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially \n",
    "unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more \n",
    "recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4331c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry Lorem Ipsum has been the industry standard dummy text ever since the 1500s when an unknown printer took galley of type and scrambled it to make type specimen book It has survived not only five centuries but also the leap into electronic typesetting remaining essentially unchanged It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\n"
     ]
    }
   ],
   "source": [
    "#Remove one letter words\n",
    "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
    "\n",
    "#Remove special characters\n",
    "sentences = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f65808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem ipsum is simply dummy text of the printing and typesetting industry lorem ipsum has been the industry standard dummy text ever since the 1500s when an unknown printer took galley of type and scrambled it to make type specimen book it has survived not only five centuries but also the leap into electronic typesetting remaining essentially unchanged it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum']\n"
     ]
    }
   ],
   "source": [
    "#Convert all letters to lowercase\n",
    "sentences = sentences.lower()\n",
    "\n",
    "#Tokenize sentences\n",
    "all_sent=nltk.sent_tokenize(sentences)\n",
    "print(all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfc4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break sentences into words\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sent]\n",
    "\n",
    "#Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i]=[w for w in all_words[i] if w not in stopwords.words('english')]\n",
    "    data = all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dbb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model using gensim\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,vector_size = 52, window = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815c02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('typesetting', 0.430533766746521)\n",
      "('1500s', 0.38891732692718506)\n",
      "('desktop', 0.2123645842075348)\n",
      "('printer', 0.210593119263649)\n",
      "('centuries', 0.20028111338615417)\n",
      "('versions', 0.17317423224449158)\n",
      "('book', 0.16240788996219635)\n",
      "('make', 0.1601787507534027)\n",
      "('ever', 0.1509247124195099)\n",
      "('specimen', 0.12824910879135132)\n"
     ]
    }
   ],
   "source": [
    "#Finding similar words to given word\n",
    "wrd='simply'\n",
    "v1=model1.wv[wrd]\n",
    "similar_words=model1.wv.most_similar(wrd)\n",
    "for x in similar_words:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec38eb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', 'lorem', 'ipsum', 'industry', 'standard', 'dummy', 'text', 'ever', 'since', '1500s', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', 'survived', 'five', 'centuries', 'also', 'leap', 'electronic', 'typesetting', 'remaining', 'essentially', 'unchanged', 'popularised', '1960s', 'release', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', 'recently', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'lorem', 'ipsum']\n"
     ]
    }
   ],
   "source": [
    "data1 = data[0]\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef2f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['lorem', 'ipsum', 'dummy', 'text'], 'simply'), (['ipsum', 'simply', 'text', 'printing'], 'dummy'), (['simply', 'dummy', 'printing', 'typesetting'], 'text'), (['dummy', 'text', 'typesetting', 'industry'], 'printing'), (['text', 'printing', 'industry', 'lorem'], 'typesetting'), (['printing', 'typesetting', 'lorem', 'ipsum'], 'industry'), (['typesetting', 'industry', 'ipsum', 'industry'], 'lorem'), (['industry', 'lorem', 'industry', 'standard'], 'ipsum'), (['lorem', 'ipsum', 'standard', 'dummy'], 'industry'), (['ipsum', 'industry', 'dummy', 'text'], 'standard'), (['industry', 'standard', 'text', 'ever'], 'dummy'), (['standard', 'dummy', 'ever', 'since'], 'text'), (['dummy', 'text', 'since', '1500s'], 'ever'), (['text', 'ever', '1500s', 'unknown'], 'since'), (['ever', 'since', 'unknown', 'printer'], '1500s'), (['since', '1500s', 'printer', 'took'], 'unknown'), (['1500s', 'unknown', 'took', 'galley'], 'printer'), (['unknown', 'printer', 'galley', 'type'], 'took'), (['printer', 'took', 'type', 'scrambled'], 'galley'), (['took', 'galley', 'scrambled', 'make'], 'type'), (['galley', 'type', 'make', 'type'], 'scrambled'), (['type', 'scrambled', 'type', 'specimen'], 'make'), (['scrambled', 'make', 'specimen', 'book'], 'type'), (['make', 'type', 'book', 'survived'], 'specimen'), (['type', 'specimen', 'survived', 'five'], 'book'), (['specimen', 'book', 'five', 'centuries'], 'survived'), (['book', 'survived', 'centuries', 'also'], 'five'), (['survived', 'five', 'also', 'leap'], 'centuries'), (['five', 'centuries', 'leap', 'electronic'], 'also'), (['centuries', 'also', 'electronic', 'typesetting'], 'leap'), (['also', 'leap', 'typesetting', 'remaining'], 'electronic'), (['leap', 'electronic', 'remaining', 'essentially'], 'typesetting'), (['electronic', 'typesetting', 'essentially', 'unchanged'], 'remaining'), (['typesetting', 'remaining', 'unchanged', 'popularised'], 'essentially'), (['remaining', 'essentially', 'popularised', '1960s'], 'unchanged'), (['essentially', 'unchanged', '1960s', 'release'], 'popularised'), (['unchanged', 'popularised', 'release', 'letraset'], '1960s'), (['popularised', '1960s', 'letraset', 'sheets'], 'release'), (['1960s', 'release', 'sheets', 'containing'], 'letraset'), (['release', 'letraset', 'containing', 'lorem'], 'sheets'), (['letraset', 'sheets', 'lorem', 'ipsum'], 'containing'), (['sheets', 'containing', 'ipsum', 'passages'], 'lorem'), (['containing', 'lorem', 'passages', 'recently'], 'ipsum'), (['lorem', 'ipsum', 'recently', 'desktop'], 'passages'), (['ipsum', 'passages', 'desktop', 'publishing'], 'recently'), (['passages', 'recently', 'publishing', 'software'], 'desktop'), (['recently', 'desktop', 'software', 'like'], 'publishing'), (['desktop', 'publishing', 'like', 'aldus'], 'software'), (['publishing', 'software', 'aldus', 'pagemaker'], 'like'), (['software', 'like', 'pagemaker', 'including'], 'aldus'), (['like', 'aldus', 'including', 'versions'], 'pagemaker'), (['aldus', 'pagemaker', 'versions', 'lorem'], 'including'), (['pagemaker', 'including', 'lorem', 'ipsum'], 'versions')]\n"
     ]
    }
   ],
   "source": [
    "#Preparing list of context words\n",
    "dat = []\n",
    "for i in range(2, len(data1) - 2):\n",
    "    context = [data1[i - 2], data1[i - 1], data1[i+1], data1[i + 2]]\n",
    "    target = data1[i]\n",
    "    dat.append((context, target))\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77aab127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['industry', 'lorem', 'industry', 'standard'] ipsum\n",
      "[('simply', 0.021740876), ('industry', 0.021740178), ('leap', 0.021739485), ('ever', 0.02173947), ('release', 0.021739446), ('including', 0.021739418), ('passages', 0.021739407), ('five', 0.021739367), ('unknown', 0.02173936), ('type', 0.02173936)]\n"
     ]
    }
   ],
   "source": [
    "#Predicting current word from context words\n",
    "i=7\n",
    "print(dat[i][0],dat[i][1])\n",
    "print(model1.predict_output_word(dat[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
